{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4a6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=2.5)\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3877ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:*******************************************************************************\n",
      "WARNING:root:*** set_global_determinism is called,setting full determinism, will be slow ***\n",
      "WARNING:root:*******************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Fixed to static seed 42.\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import logging\n",
    "\n",
    "\n",
    "SEED =42\n",
    "\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.compat.v1.set_random_seed(seed) # ver1\n",
    "    # tf.random.set_seed(seed) # ver 2\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def set_global_determinism(seed=SEED, fast_n_close=False):\n",
    "    \"\"\"\n",
    "        Enable 100% reproducibility on operations related to tensor and randomness.\n",
    "        Parameters:\n",
    "        seed (int): seed value for global randomness\n",
    "        fast_n_close (bool): whether to achieve efficient at the cost of determinism/reproducibility\n",
    "    \"\"\"\n",
    "    set_seeds(seed=seed)\n",
    "    if fast_n_close:\n",
    "        return\n",
    "\n",
    "    logging.warning(\"*******************************************************************************\")\n",
    "    logging.warning(\"*** set_global_determinism is called,setting full determinism, will be slow ***\")\n",
    "    logging.warning(\"*******************************************************************************\")\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/config/threading/set_inter_op_parallelism_threads\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "    \n",
    "# set_seeds(42)\n",
    "# set_global_determinism(42)\n",
    "\n",
    "set_seeds(42)\n",
    "set_global_determinism(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703227ce",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56813e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Menopause</th>\n",
       "      <th>Method</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA125 (IU/ml)</th>\n",
       "      <th>Myometrial invasion depth</th>\n",
       "      <th>Tumor size (largest diameter)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Dilatation/currettage</td>\n",
       "      <td>I</td>\n",
       "      <td>14.94</td>\n",
       "      <td>Less than 50% (&lt; 1/2)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Dilatation/currettage</td>\n",
       "      <td>I</td>\n",
       "      <td>20.38</td>\n",
       "      <td>None</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>Dilatation/currettage</td>\n",
       "      <td>I</td>\n",
       "      <td>43.47</td>\n",
       "      <td>Less than 50% (&lt; 1/2)</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Dilatation/currettage</td>\n",
       "      <td>I</td>\n",
       "      <td>13.83</td>\n",
       "      <td>Less than 50% (&lt; 1/2)</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Dilatation/currettage</td>\n",
       "      <td>I</td>\n",
       "      <td>9.02</td>\n",
       "      <td>Less than 50% (&lt; 1/2)</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Menopause                 Method Grade  CA125 (IU/ml)  \\\n",
       "0   54       Yes  Dilatation/currettage     I          14.94   \n",
       "1   55       Yes  Dilatation/currettage     I          20.38   \n",
       "2   45        No  Dilatation/currettage     I          43.47   \n",
       "3   62       Yes  Dilatation/currettage     I          13.83   \n",
       "4   55       Yes  Dilatation/currettage     I           9.02   \n",
       "\n",
       "  Myometrial invasion depth Tumor size (largest diameter)  \n",
       "0     Less than 50% (< 1/2)                             3  \n",
       "1                      None                           1.7  \n",
       "2     Less than 50% (< 1/2)                          1.25  \n",
       "3     Less than 50% (< 1/2)                           4.7  \n",
       "4     Less than 50% (< 1/2)                           1.3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preoperative data\n",
    "data = pd.read_csv('data/train.csv')\n",
    "data.drop(['Unnamed: 3','Unnamed: 7','Patient Initials', 'Histologic type'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d367702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Route</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Histologic diagnosis</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Myometrial invasion depth</th>\n",
       "      <th>Tumor size (largest diameter)</th>\n",
       "      <th>Extrauterine involvement</th>\n",
       "      <th>Lymphovascular space invasion (LVSI)</th>\n",
       "      <th>Metastasis of pelvic lymph node</th>\n",
       "      <th>Metastasis of para-aortic lymph node</th>\n",
       "      <th>LN metastasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Laparoscopic</td>\n",
       "      <td>Ia</td>\n",
       "      <td>Endometrioid</td>\n",
       "      <td>I</td>\n",
       "      <td>Less than 50%</td>\n",
       "      <td>2.5</td>\n",
       "      <td>none</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laparoscopic</td>\n",
       "      <td>Ia</td>\n",
       "      <td>Endometrioid</td>\n",
       "      <td>I</td>\n",
       "      <td>Less than 50%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laparoscopic</td>\n",
       "      <td>Ia</td>\n",
       "      <td>Endometrioid</td>\n",
       "      <td>I</td>\n",
       "      <td>Less than 50%</td>\n",
       "      <td>3.8</td>\n",
       "      <td>none</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laparoscopic</td>\n",
       "      <td>Ia</td>\n",
       "      <td>Endometrioid</td>\n",
       "      <td>I</td>\n",
       "      <td>Less than 50%</td>\n",
       "      <td>4.0</td>\n",
       "      <td>none</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laparoscopic</td>\n",
       "      <td>Ia</td>\n",
       "      <td>Endometrioid</td>\n",
       "      <td>I</td>\n",
       "      <td>Less than 50%</td>\n",
       "      <td>2.0</td>\n",
       "      <td>none</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Route Stage Histologic diagnosis Grade Myometrial invasion depth  \\\n",
       "0  Laparoscopic    Ia         Endometrioid     I             Less than 50%   \n",
       "1  Laparoscopic    Ia         Endometrioid     I             Less than 50%   \n",
       "2  Laparoscopic    Ia         Endometrioid     I             Less than 50%   \n",
       "3  Laparoscopic    Ia         Endometrioid     I             Less than 50%   \n",
       "4  Laparoscopic    Ia         Endometrioid     I             Less than 50%   \n",
       "\n",
       "   Tumor size (largest diameter) Extrauterine involvement  \\\n",
       "0                            2.5                     none   \n",
       "1                            1.0                     none   \n",
       "2                            3.8                     none   \n",
       "3                            4.0                     none   \n",
       "4                            2.0                     none   \n",
       "\n",
       "  Lymphovascular space invasion (LVSI) Metastasis of pelvic lymph node  \\\n",
       "0                                   No                               0   \n",
       "1                                   No                               0   \n",
       "2                                   No                               0   \n",
       "3                                   No                               0   \n",
       "4                                   No                               0   \n",
       "\n",
       "   Metastasis of para-aortic lymph node LN metastasis  \n",
       "0                                     0            no  \n",
       "1                                     0            no  \n",
       "2                                     0            no  \n",
       "3                                     0            no  \n",
       "4                                     0            no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PostOperative data\n",
    "label_data = pd.read_csv('data/label.csv')\n",
    "label_data.drop(['Unnamed: 7'], axis=1, inplace=True)\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba49af3d",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a332c05",
   "metadata": {},
   "source": [
    "### Add 'pre_GN' and 'post_GN' variabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4ef71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_GN(grade, invasion):\n",
    "    if grade == 'I' and invasion == 'None': # Group 1\n",
    "        return 0\n",
    "    elif grade == 'II' and invasion == 'None': # Group 2\n",
    "        return 1\n",
    "    elif grade == 'I' and invasion == 'Less than 50% (< 1/2)': # Group 3\n",
    "        return 2\n",
    "    elif grade == 'II' and invasion == 'Less than 50% (< 1/2)': # Group 4\n",
    "        return 3\n",
    "    else: # Others\n",
    "        return 4\n",
    "    \n",
    "def post_GN(stage, grade, invasion):\n",
    "    if stage == 'Ia':\n",
    "        if grade == 'I' and invasion == 'None': # Group 1\n",
    "            return 0\n",
    "        elif grade == 'II' and invasion == 'None': # Group 2\n",
    "            return 1\n",
    "        elif grade == 'I' and invasion == 'Less than 50%': # Group 3\n",
    "            return 2\n",
    "        elif grade == 'II' and invasion == 'Less than 50%': # Group 4\n",
    "            return 3\n",
    "        else: # others. Stage is 1A but Grade is III or invasion is More than 50%.\n",
    "            return 4\n",
    "    else: # others. All if Stage is not 1A.\n",
    "        return 4\n",
    "\n",
    "\n",
    "data['pre_GN'] = data.apply(lambda x: pre_GN(x['Grade'], x['Myometrial invasion depth']), axis=1)\n",
    "data['post_GN'] = label_data.apply(lambda x: post_GN(x['Stage'], x['Grade'], x['Myometrial invasion depth']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffbd1b",
   "metadata": {},
   "source": [
    "### Processing the 'Tumor size' .value(null)\n",
    "Fill in with the average tumor size for each post-operative invasion depth group\n",
    "* None: 1.41\n",
    "* Less than 50%: 2.44\n",
    "* More than 50%: 2.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530a1d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '1.7', '1.25', '4.7', '1.3', '2.3', '5.5', '0.6', '2', '.',\n",
       "       '3.7', '4.2', '1.5', '2.9', '2.2', '3.3', '5', '2.8', '0', '2.5',\n",
       "       '1.8', '5.8', '0.1', '4', '1', '2.6', '7.58', '3.4', '2.1', '3.5',\n",
       "       '1.2', '1.1', '4.5', '3.6', '0.9', '5.7', '3.1', '2.7', '0.8',\n",
       "       '2.4', '4.1', '1.6', '1.9', '8.3', '3.2', '4.4', '1.45', '17',\n",
       "       '3.9', '0.5'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tumor size (largest diameter)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9eca521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    252.000000\n",
       "mean       2.098413\n",
       "std        1.592011\n",
       "min        0.000000\n",
       "25%        0.800000\n",
       "50%        2.000000\n",
       "75%        3.000000\n",
       "max        8.200000\n",
       "Name: Tumor size (largest diameter), dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data['Tumor size (largest diameter)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc02a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None_num: 1.41, Less_num: 2.45, More_num: 2.95\n"
     ]
    }
   ],
   "source": [
    "None_num = round(label_data[label_data['Myometrial invasion depth']=='None']['Tumor size (largest diameter)'].mean(), 2)\n",
    "Less_num = round(label_data[label_data['Myometrial invasion depth']=='Less than 50%']['Tumor size (largest diameter)'].mean(), 2)\n",
    "More_num = round(label_data[label_data['Myometrial invasion depth']=='More than 50%']['Tumor size (largest diameter)'].mean(), 2)\n",
    "\n",
    "print(f\"None_num: {None_num}, Less_num: {Less_num}, More_num: {More_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c659c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if data['Tumor size (largest diameter)'][i] == '.': # If Tumor size is '.',\n",
    "        # If the invasion depth is None, replace with the average value of 1.41\n",
    "        if data['Myometrial invasion depth'][i] == 'None':\n",
    "            data['Tumor size (largest diameter)'][i] = None_num\n",
    "        # If the invasion depth is less than 50%, replace with the average value of 2.44\n",
    "        elif data['Myometrial invasion depth'][i] == 'Less than 50% (< 1/2)':\n",
    "            data['Tumor size (largest diameter)'][i] =  Less_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bcdc1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '1.7', '1.25', '4.7', '1.3', '2.3', '5.5', '0.6', '2', 2.45,\n",
       "       '3.7', '4.2', '1.5', '2.9', '2.2', 1.41, '3.3', '5', '2.8', '0',\n",
       "       '2.5', '1.8', '5.8', '0.1', '4', '1', '2.6', '7.58', '3.4', '2.1',\n",
       "       '3.5', '1.2', '1.1', '4.5', '3.6', '0.9', '5.7', '3.1', '2.7',\n",
       "       '0.8', '2.4', '4.1', '1.6', '1.9', '8.3', '3.2', '4.4', '1.45',\n",
       "       '17', '3.9', '0.5'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tumor size (largest diameter)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "076378b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dtype of tumor size to float\n",
    "data['Tumor size (largest diameter)'] = data['Tumor size (largest diameter)'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b6ad3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Myometrial invasion depth'] = data['Myometrial invasion depth'].replace('Less than 50% (< 1/2)', 'Less than 50%')\n",
    "\n",
    "label_data['Myometrial invasion depth2'] = label_data['Myometrial invasion depth']\n",
    "label_data['Myometrial invasion depth2'] = label_data['Myometrial invasion depth2'].replace('None', 0)\n",
    "label_data['Myometrial invasion depth2'] = label_data['Myometrial invasion depth2'].replace('Less than 50%', 1)\n",
    "label_data['Myometrial invasion depth2'] = label_data['Myometrial invasion depth2'].replace('More than 50%', 2)\n",
    "\n",
    "label_data['Grade2'] = label_data['Grade']\n",
    "label_data['Grade2'] = label_data['Grade2'].replace('I', 0)\n",
    "label_data['Grade2'] = label_data['Grade2'].replace('II', 1)\n",
    "label_data['Grade2'] = label_data['Grade2'].replace('others', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977fb8d",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5344758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to separate data into df_P and df_F, and decide the number of splits\n",
    "def make_seperate_n_splits(daf):\n",
    "    # Separate into df_P where 'post_GN' is True\n",
    "    df_P = daf[daf['post_GN'] == True]\n",
    "    df_P.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Separate into df_F where 'post_GN' is False\n",
    "    df_F = daf[daf['post_GN'] == False]\n",
    "    df_F.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Determine the number of splits based on the length of each category\n",
    "    daf_len_True = len(daf[daf['post_GN'] == True])\n",
    "    daf_len_False = len(daf[daf['post_GN'] == False])\n",
    "    n_split = round(daf_len_False / daf_len_True, 0) # Calculate n_split, rounding to ensure it's an integer\n",
    "    n_split = int(n_split)\n",
    "    \n",
    "    return df_P, df_F, n_split\n",
    "\n",
    "# Function to create balanced datasets ensuring equal representation from minority class (e.g., False: 144, True: 57)\n",
    "def make_balanced_dataset(n_split, df_F):\n",
    "    data_kf = KFold(n_splits=n_split, shuffle=True, random_state=50)\n",
    "    df_list = []\n",
    "    # Create datasets with balanced classes using K-Fold cross-validation on the majority class\n",
    "    for train_index, test_index in data_kf.split(df_F):\n",
    "        X_train, X_test = df_F.iloc[train_index, :], df_F.iloc[test_index, :]\n",
    "\n",
    "        # Combine the test split of majority class with the entire minority class, then reset index\n",
    "        daf = pd.concat([X_test, df_P], axis=0)\n",
    "        daf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_list.append(daf)\n",
    "        \n",
    "    return df_list\n",
    "\n",
    "\n",
    "# Sort dictionary values in descending order and select models based on base score\n",
    "def make_max_score_model_selection(lists, base_score):\n",
    "    # Create a boolean array where True if the score is greater than or equal to base_score\n",
    "    k = np.array(lists) >= base_score\n",
    "    \n",
    "    # Collect indices of True values\n",
    "    model_index = []\n",
    "    for i in range(len(k)):\n",
    "        if k[i] == True:\n",
    "            model_index.append(i)\n",
    "            \n",
    "    return model_index\n",
    "\n",
    "# Return True if the value is greater than 0.5, otherwise False\n",
    "def make_valuessss(values):\n",
    "    if values > 0.5:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Calculate and return the average of predict_proba from selected models\n",
    "def cal_pred_proba_test(model_index):\n",
    "    # Select models that meet the condition based on model_index\n",
    "    selected_model = []\n",
    "    for i in model_index:\n",
    "        selected_model.append(LR_random_list[i])\n",
    "        \n",
    "    # Calculate the average predict_proba from selected models\n",
    "    pred_proba = []\n",
    "    # Store each model's predict_proba result into a list\n",
    "    for j in range(len(selected_model)):\n",
    "        pred_proba.append(selected_model[j].predict_proba(X_test))\n",
    "        \n",
    "    # Compute the mean of the stored predict_proba results\n",
    "    c = 0\n",
    "    for j in range(len(pred_proba)):\n",
    "        c += pred_proba[j]\n",
    "    mean_score = c / len(pred_proba)  # Average out the accumulated probabilities\n",
    "    \n",
    "    # Convert average scores to DataFrame and calculate mean y_pred\n",
    "    mean_score = pd.DataFrame(mean_score)    \n",
    "    cal_mean_score_list.append(mean_score[1])\n",
    "    \n",
    "    # Apply threshold to determine the final prediction labels\n",
    "    y_pred = mean_score[1].apply(make_valuessss)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_cm_list_5(cm_list):    \n",
    "    TP_list, FN_list, FP_list, TN_list = [], [], [], []\n",
    "    for i in range(5):    \n",
    "        TP, FN, FP, TN = cm_list[i].ravel()\n",
    "        TP_list.append(TP)\n",
    "        FN_list.append(FN)\n",
    "        FP_list.append(FP)\n",
    "        TN_list.append(TN)\n",
    "\n",
    "    sum_TP = sum(TP_list)\n",
    "    sum_FN = sum(FN_list)\n",
    "    sum_FP = sum(FP_list)\n",
    "    sum_TN = sum(TN_list)\n",
    "\n",
    "    print(f'TP: {sum_TP},  FP: {sum_FP}, FN: {sum_FN}, TN: {sum_TN}')\n",
    "    \n",
    "    y_true = []\n",
    "    # 0: others\n",
    "    for i in range(sum_FP+sum_TN): # others total count (False total count FP + TN)\n",
    "        y_true.append(0)\n",
    "\n",
    "    for i in range(sum_TP+sum_FN): # Group 1 Total Count (True Total Count TP + FN)\n",
    "        y_true.append(1)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in range(sum_TN): # TN\n",
    "        y_pred.append(0)\n",
    "\n",
    "    for i in range(sum_FP): # FP\n",
    "        y_pred.append(1)\n",
    "\n",
    "    for i in range(sum_FN): # FN\n",
    "        y_pred.append(0)\n",
    "\n",
    "    for i in range(sum_TP): # TP\n",
    "        y_pred.append(1)\n",
    "    \n",
    "    roc_auc_scores = round(roc_auc_score(y_true, y_pred), 4)\n",
    "    \n",
    "    print(round(roc_auc_score(y_true, y_pred), 4))\n",
    "    \n",
    "    return sum_TP, sum_FP, sum_FN, sum_TN, roc_auc_scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_imputation_mice_lr_invasion(X_train, X_test_data):\n",
    "    X_train_index = X_train.index    \n",
    "    X_train_columns = X_train.columns\n",
    "    \n",
    "    X_test_data_idx = X_test_data.index\n",
    "    X_test_data_col = X_test_data.columns\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    imputer = IterativeImputer(estimator=lr, missing_values=np.nan, max_iter=10, verbose=0, imputation_order='random',random_state=42)\n",
    "    \n",
    "    # Handle train\n",
    "    X_train = imputer.fit_transform(X_train)    \n",
    "    X_train = pd.DataFrame(X_train, index = X_train_index, columns = X_train_columns)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Predicted invasion depth in X_test_data.\n",
    "    X_test_data = pd.DataFrame(X_test_data, columns=X_train.columns)\n",
    "    X_test_data.loc[:, 'Myometrial invasion depth'] = np.nan # Handling test set-wide missing\n",
    "    \n",
    "    X_test_data = imputer.transform(X_test_data)\n",
    "    X_test_data = pd.DataFrame(X_test_data, index = X_test_data_idx, columns = X_test_data_col)\n",
    "\n",
    "    \n",
    "    return X_train, X_test_data\n",
    "\n",
    "\n",
    "def calc_valid_auc(sum_TP, sum_FP, sum_FN, sum_TN):\n",
    "    y_true = []\n",
    "    # 0: others\n",
    "    for i in range(sum_FP+sum_TN): # others total count (False total count FP + TN)\n",
    "        y_true.append(0)\n",
    "\n",
    "    for i in range(sum_TP+sum_FN): # Group 1 Total Count (True Total Count TP + FN)\n",
    "        y_true.append(1)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in range(sum_TN): # TN\n",
    "        y_pred.append(0)\n",
    "\n",
    "    for i in range(sum_FP): # FP\n",
    "        y_pred.append(1)\n",
    "\n",
    "    for i in range(sum_FN): # FN\n",
    "        y_pred.append(0)\n",
    "\n",
    "    for i in range(sum_TP): # TP\n",
    "        y_pred.append(1)\n",
    "    \n",
    "    try:\n",
    "        roc_auc_scores = round(roc_auc_score(y_true, y_pred), 4)\n",
    "    except:\n",
    "        roc_auc_scores=0.5    \n",
    "    \n",
    "    return roc_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "801d2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_logistic(X_data, y_label, y_label_len, i, q):\n",
    "    model_kf = KFold(n_splits = y_label_len, shuffle = True, random_state = 50)  \n",
    "\n",
    "     # Train a Logistic Regression model on each balanced dataset\n",
    "    for idx, (train_index, test_index) in enumerate(model_kf.split(X_data)):\n",
    "        X_train_model, X_test_model = X_data[train_index], X_data[test_index]\n",
    "        y_train_model, y_test_model = y_label[train_index], y_label[test_index]\n",
    "\n",
    "        LR_clf = LogisticRegression()\n",
    "\n",
    "        solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "        penalty = ['l2', 'l1']\n",
    "        c_values = [1000, 100, 10, 1.0, 0.1, 0.01, 0.001] # Range of C values\n",
    "\n",
    "        # define grid search\n",
    "        grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "        \n",
    "        \n",
    "        # Create a RandomizedSearchCV object to tune the Logistic Regression\n",
    "        LR_random = RandomizedSearchCV(estimator=LR_clf,\n",
    "                                       param_distributions=grid,\n",
    "                                       n_iter=40,  # Number of parameter settings sampled\n",
    "                                       scoring='f1_macro',  # Scoring metric\n",
    "                                       n_jobs=-1,  # Use all cores\n",
    "                                       cv=3,  # 3-fold cross-validation\n",
    "                                       random_state=42,\n",
    "                                       refit=True,\n",
    "                                       return_train_score=True)\n",
    "                \n",
    "\n",
    "        grid_result = LR_random.fit(X_train_model, y_train_model)\n",
    "\n",
    "        # predict\n",
    "        pred_train_model = grid_result.best_estimator_.predict(X_train_model)\n",
    "        y_pred_model = grid_result.best_estimator_.predict(X_test_model)\n",
    "        \n",
    "        X_valid_list.append(X_test_model) # valid set\n",
    "        y_valid_list.append(y_test_model)\n",
    "        \n",
    "        LR_random_list.append(grid_result.best_estimator_)\n",
    "\n",
    "\n",
    "        train_accuracy.append(accuracy_score(y_train_model, pred_train_model))\n",
    "        test_accuracy.append(accuracy_score(y_test_model, y_pred_model))\n",
    "        macro_average.append(f1_score(y_test_model, y_pred_model, average='macro'))\n",
    "        True_recall_list.append(recall_score(y_test_model, y_pred_model))\n",
    "        # roc_auc_list.append(roc_auc_score(y_test_model, y_pred_model))\n",
    "        precision_list.append(precision_score(y_test_model, y_pred_model))\n",
    "\n",
    "        y_test_list.append(np.array(y_test_model))\n",
    "        y_pred_list.append(y_pred_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364eb973",
   "metadata": {},
   "source": [
    "# Data processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "189c3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# n = 0: group 1,n = 1: group 2\n",
    "def data_processing(data, n):\n",
    "    numerical_features = data.select_dtypes(include=['int64', 'float64']).iloc[:, :-2]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(numerical_features)\n",
    "    numerical_features_scaled = scaler.transform(numerical_features)\n",
    "\n",
    "    numerical_features_scaled = pd.DataFrame(numerical_features_scaled, columns=numerical_features.columns)\n",
    "    numerical_features_scaled = pd.concat([numerical_features_scaled, data.iloc[:, -2:]], axis=1)\n",
    "\n",
    "    # One-Hot encoding the categorical features using get_dummies()\n",
    "    # select categorical features\n",
    "    categorical_features = data.select_dtypes(include=['object'])\n",
    "\n",
    "    # Grade I: 0, Grade II: 1\n",
    "    categorical_features['Grade'] = categorical_features['Grade'].replace('I', 0)\n",
    "    categorical_features['Grade'] = categorical_features['Grade'].replace('II', 1)\n",
    "    categorical_features['Myometrial invasion depth'] = categorical_features['Myometrial invasion depth'].replace('None', 0)\n",
    "    categorical_features['Myometrial invasion depth'] = categorical_features['Myometrial invasion depth'].replace('Less than 50%', 1)\n",
    "    categorical_features = pd.get_dummies(categorical_features)\n",
    "\n",
    "    combined = pd.concat([numerical_features_scaled, categorical_features], axis=1)\n",
    "\n",
    "    # seperate features and target\n",
    "    X = combined\n",
    "        \n",
    "    # To use the Invasion depth value as is.\n",
    "    X['pre_Myometrial invasion depth'] = X['Myometrial invasion depth']        \n",
    "    # X['pre_Grade'] = X['Grade'] \n",
    " \n",
    "    \n",
    "    y = (X['post_GN'] == n)\n",
    "    print(y.value_counts())\n",
    "    \n",
    "    \n",
    "    X.drop(columns=['pre_GN', 'post_GN'], inplace=True)\n",
    "\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d267e",
   "metadata": {},
   "source": [
    "# NPM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "178b69fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    184\n",
      "True      67\n",
      "Name: post_GN, dtype: int64\n",
      "************ Group 1 ***************\n",
      "Index(['Age', 'CA125 (IU/ml)', 'Tumor size (largest diameter)', 'Grade',\n",
      "       'Myometrial invasion depth', 'Menopause_No', 'Menopause_Yes',\n",
      "       'Method_Dilatation/currettage', 'Method_Hysteroscopy',\n",
      "       'Method_Pipelle biopsy', 'pre_Myometrial invasion depth'],\n",
      "      dtype='object')\n",
      "Index(['Age', 'CA125 (IU/ml)', 'Tumor size (largest diameter)', 'Grade',\n",
      "       'Myometrial invasion depth', 'Menopause_No', 'Menopause_Yes',\n",
      "       'Method_Dilatation/currettage', 'Method_Hysteroscopy',\n",
      "       'Method_Pipelle biopsy'],\n",
      "      dtype='object')\n",
      "All Match rate: 58.17%\n",
      "imputated vs pre invasion, Match rate: 100.00%\n",
      "TP: 48,  FP: 68, FN: 19, TN: 116\n",
      "0.6734\n",
      "\n",
      "False    237\n",
      "True      14\n",
      "Name: post_GN, dtype: int64\n",
      "************ Group 2 ***************\n",
      "Index(['Age', 'CA125 (IU/ml)', 'Tumor size (largest diameter)', 'Grade',\n",
      "       'Myometrial invasion depth', 'Menopause_No', 'Menopause_Yes',\n",
      "       'Method_Dilatation/currettage', 'Method_Hysteroscopy',\n",
      "       'Method_Pipelle biopsy', 'pre_Myometrial invasion depth'],\n",
      "      dtype='object')\n",
      "Index(['Age', 'CA125 (IU/ml)', 'Tumor size (largest diameter)', 'Grade',\n",
      "       'Myometrial invasion depth', 'Menopause_No', 'Menopause_Yes',\n",
      "       'Method_Dilatation/currettage', 'Method_Hysteroscopy',\n",
      "       'Method_Pipelle biopsy'],\n",
      "      dtype='object')\n",
      "All Match rate: 58.17%\n",
      "imputated vs pre invasion, Match rate: 100.00%\n",
      "TP: 11,  FP: 114, FN: 3, TN: 123\n",
      "0.6524\n",
      "\n",
      "False    153\n",
      "True      98\n",
      "Name: post_GN, dtype: int64\n",
      "************ Group 3 ***************\n",
      "Index(['Age', 'CA125 (IU/ml)', 'Tumor size (largest diameter)', 'Grade',\n",
      "       'Myometrial invasion depth', 'Menopause_No', 'Menopause_Yes',\n",
      "       'Method_Dilatation/currettage', 'Method_Hysteroscopy',\n",
      "       'Method_Pipelle biopsy', 'pre_Myometrial invasion depth'],\n",
      "      dtype='object')\n",
      "Index(['Age', 'CA125 (IU/ml)', 'Tumor size (largest diameter)', 'Grade',\n",
      "       'Myometrial invasion depth', 'Menopause_No', 'Menopause_Yes',\n",
      "       'Method_Dilatation/currettage', 'Method_Hysteroscopy',\n",
      "       'Method_Pipelle biopsy'],\n",
      "      dtype='object')\n",
      "All Match rate: 58.17%\n",
      "imputated vs pre invasion, Match rate: 100.00%\n",
      "TP: 77,  FP: 102, FN: 21, TN: 51\n",
      "0.5595\n",
      "\n",
      "False    214\n",
      "True      37\n",
      "Name: post_GN, dtype: int64\n",
      "************ Group 4 ***************\n",
      "Index(['Age', 'CA125 (IU/ml)', 'Tumor size (largest diameter)', 'Grade',\n",
      "       'Myometrial invasion depth', 'Menopause_No', 'Menopause_Yes',\n",
      "       'Method_Dilatation/currettage', 'Method_Hysteroscopy',\n",
      "       'Method_Pipelle biopsy', 'pre_Myometrial invasion depth'],\n",
      "      dtype='object')\n",
      "Index(['Age', 'CA125 (IU/ml)', 'Tumor size (largest diameter)', 'Grade',\n",
      "       'Myometrial invasion depth', 'Menopause_No', 'Menopause_Yes',\n",
      "       'Method_Dilatation/currettage', 'Method_Hysteroscopy',\n",
      "       'Method_Pipelle biopsy'],\n",
      "      dtype='object')\n",
      "All Match rate: 58.17%\n",
      "imputated vs pre invasion, Match rate: 100.00%\n",
      "TP: 24,  FP: 79, FN: 13, TN: 135\n",
      "0.6397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import shap\n",
    "\n",
    "seed = 955\n",
    "\n",
    "best_roc_auc_scores = 0\n",
    "best_sum_TP =0\n",
    "best_sum_FP =0\n",
    "best_sum_FN =0\n",
    "best_sum_TN =0\n",
    "best_z = 0\n",
    "roc_auc_scores_valid_list = []\n",
    "base_auc_score_list=[]\n",
    "score_auc_count_list=[]\n",
    "roc_auc_scores_test_list_list=[]\n",
    "base_score_list_list=[]\n",
    "max_count_score_list_list=[]\n",
    "\n",
    "base_score_rs_list = [] # Average of Score(Max((TP+TN)-(FP+FN))*0.999 for all folds by random state\n",
    "\n",
    "valid_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "test_index_list = []\n",
    "cal_mean_score_list = []\n",
    "\n",
    "\n",
    "roc_auc_scores_test_list = []\n",
    "base_score_list = []\n",
    "max_count_score_list = []\n",
    "for q in range(4): # q is the Group that predicts\n",
    "    X, y = data_processing(data, q)  \n",
    "    \n",
    "\n",
    "    \n",
    "    print(f'************ Group {q+1} ***************')\n",
    "\n",
    "    # Number of splits, shuffle or not, and seed settings\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)    \n",
    "\n",
    "    cm_valid_list = []\n",
    "    cm_test_list = []\n",
    "    None_concordance_all = 0\n",
    "    Less_concordance_all = 0\n",
    "    \n",
    "    columns = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "    TP_result = pd.DataFrame(columns = columns)\n",
    "    FN_result = pd.DataFrame(columns = columns)\n",
    "    FP_result = pd.DataFrame(columns = columns)\n",
    "    TN_result = pd.DataFrame(columns = columns)\n",
    "    result_cm_list=[]\n",
    "    original_test_inv_data_list = []\n",
    "    label_y_test_list = []\n",
    "    X_test_data_pre_invasion = []\n",
    "    prob_test_inv_data_list = []\n",
    "\n",
    "    # Split the train and test datasets by the number of split steps each time.\n",
    "    for n, (train_index, test_index) in enumerate(skf.split(X, y)):    \n",
    "        train_accuracy = []\n",
    "        test_accuracy = []\n",
    "        macro_average = []\n",
    "        y_test_list = []\n",
    "        y_pred_list = []\n",
    "        True_recall_list = []\n",
    "        roc_auc_list = []\n",
    "        precision_list = []\n",
    "        best_estimator = []\n",
    "        max_count_list = []\n",
    "        valid_roc_auc_scores_list=[]\n",
    "        \n",
    "        X_train, X_test_data = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]        \n",
    "        # Adding label invasion depth\n",
    "        label_y_train, label_y_test = label_data.loc[train_index, 'Myometrial invasion depth2'], label_data.loc[test_index, 'Myometrial invasion depth2']\n",
    "\n",
    "        if n==1:\n",
    "            print(X_train.columns)\n",
    "\n",
    "        test_index_list.append(test_index)\n",
    "\n",
    "        # X_train의 index\n",
    "        trn_idx = X_train.index\n",
    "        tst_idx = X_test_data.index                        \n",
    "\n",
    "\n",
    "        # handle train set missing (invasion depth)\n",
    "        # Extract indexes with mismatched pre- and post-op invasions\n",
    "        not_concordance_invasion_idx = X_train[(X_train.loc[trn_idx, 'Myometrial invasion depth'] != label_data.loc[trn_idx, 'Myometrial invasion depth2'])].index\n",
    "        # Handling missing data with mismatched perioperative invasions\n",
    "        X_train.loc[not_concordance_invasion_idx, 'Myometrial invasion depth'] = np.nan\n",
    "        num_missing_invasion = X_train['Myometrial invasion depth'].isnull().sum()        \n",
    "\n",
    "\n",
    "        # invasion imputation\n",
    "        X_train, X_test_data = make_imputation_mice_lr_invasion(X_train, X_test_data)      \n",
    "\n",
    "        # Compare matching on invasion depth imputaton\n",
    "        # label invasion depth (original)\n",
    "        original_test_inv_data = np.where(X_test_data['Myometrial invasion depth'] >= 0.5, 1, 0).tolist() # (이전 값) 0.5 이상은 1, 0.5이하는 0 \n",
    "        prob_test_inv_data = X_test_data['Myometrial invasion depth']\n",
    "        \n",
    "        original_test_inv_data_list.extend(original_test_inv_data)\n",
    "        label_y_test_list.extend(label_y_test)\n",
    "        prob_test_inv_data_list.extend(prob_test_inv_data)\n",
    "\n",
    "\n",
    "        X_test_data_pre_invasion.extend(X_test_data['pre_Myometrial invasion depth'])\n",
    "\n",
    "\n",
    "        # Remove pre Myometrial invasion depth \n",
    "        X_train = X_train.drop(columns=['pre_Myometrial invasion depth'])\n",
    "        X_test_data = X_test_data.drop(columns=['pre_Myometrial invasion depth'])\n",
    "\n",
    "\n",
    "        if n==1:\n",
    "            print(X_train.columns)\n",
    "\n",
    "\n",
    "        X_test = np.array(X_test_data)\n",
    "        \n",
    "        # X_train, y_train by column, and then append \n",
    "        daf = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "        # Determine the number of df_P, df_F splits and n_splits\n",
    "        df_P, df_F, n_split = make_seperate_n_splits(daf)\n",
    "\n",
    "        # If n_split == 1, add 1.\n",
    "        if n_split == 1:\n",
    "            n_split+=1 \n",
    "\n",
    "\n",
    "        df_list = make_balanced_dataset(n_split, df_F)\n",
    "\n",
    "\n",
    "        n_iter = 0\n",
    "        # as many for statements as there are datasets created. \n",
    "        LR_random_list = []\n",
    "        xgb_random_list=[]\n",
    "        X_valid_list=[]\n",
    "        y_valid_list=[]\n",
    "        for i in range(n_split):\n",
    "            # iteration as many times as there are datasets\n",
    "            n_iter += 1\n",
    "            y_label = df_list[i]['post_GN']\n",
    "            drop_data = df_list[i].drop(columns=['post_GN'])            \n",
    "\n",
    "            X_data = np.array(drop_data.iloc[:, :])\n",
    "            \n",
    "            y_label_len = len(y_label)\n",
    "            make_logistic(X_data, y_label, 5, i, q)            \n",
    "\n",
    "\n",
    "        # select & predict with models with large (TP+TN)-(FP+FN) values\n",
    "        for j in range(len(LR_random_list)): \n",
    "\n",
    "            y_pred = LR_random_list[j].predict(X_valid_list[j])\n",
    "\n",
    "            cm = confusion_matrix(y_valid_list[j], y_pred, labels=[1, 0]).ravel()\n",
    "            TP_value, FN_value, FP_value, TN_value = cm.ravel()\n",
    "\n",
    "            valid_roc_auc_scores = calc_valid_auc(TP_value, FP_value, FN_value, TN_value)\n",
    "            valid_roc_auc_scores_list.append(valid_roc_auc_scores)\n",
    "\n",
    "            max_count = (TP_value + TN_value) - (FN_value + FP_value)\n",
    "            max_count_list.append(max_count)        \n",
    "        \n",
    "\n",
    "        # Calculate confidence intervals\n",
    "        base_score = max(max_count_list) * 0.999\n",
    "        base_score_list.append(base_score)\n",
    "\n",
    "        # Calculate AUC\n",
    "        base_auc_score = max(valid_roc_auc_scores_list) * 0.999\n",
    "        base_auc_score_list.append(base_auc_score)\n",
    "\n",
    "        # of models above max auc score (number to ensemble)\n",
    "        score_auc_count = np.where(valid_roc_auc_scores_list > base_auc_score)[0]\n",
    "        score_auc_count_list.append(len(score_auc_count))\n",
    "        \n",
    "        o = max_count_list.count(max(max_count_list))\n",
    "        max_count_score_list.append(o)\n",
    "\n",
    "        # extract model index higher than base_score\n",
    "        model_index = make_max_score_model_selection(max_count_list, base_score)\n",
    "\n",
    "        # Ensemble | prediction proba average (X_test) / return y_pred \n",
    "        mean_y_pred_test = cal_pred_proba_test(model_index)\n",
    "\n",
    "\n",
    "        # Evaluation metrics (test)\n",
    "        macro_score = f1_score(mean_y_pred_test, y_test, average='macro')\n",
    "\n",
    "        cm_test = confusion_matrix(y_test, mean_y_pred_test, labels=[1, 0])\n",
    "        cm_test_list.append(cm_test)\n",
    "\n",
    "        \n",
    "    # include only exact matches for the entire list.\n",
    "    matches = sum(i == j for i, j in zip(original_test_inv_data_list, label_y_test_list)) # 일치한 것 확인\n",
    "    total = len(original_test_inv_data_list)\n",
    "\n",
    "    match_rate = matches / total\n",
    "\n",
    "    print(f'All Match rate: {match_rate*100:.2f}%')\n",
    "    \n",
    "    matches_w_pre_inv = sum(i == j for i, j in zip(original_test_inv_data_list, X_test_data_pre_invasion)) # 일치한 것 확인\n",
    "    total = len(original_test_inv_data_list)\n",
    "\n",
    "    match_rate_w_pre_inv = matches_w_pre_inv / total\n",
    "\n",
    "    print(f'imputated vs pre invasion, Match rate: {match_rate_w_pre_inv*100:.2f}%')\n",
    "\n",
    "\n",
    "    # store the average of the base scores from the valid set from each fold\n",
    "    base_score_rs_list.append(np.mean(base_score_list))\n",
    "\n",
    "    # Calculate TP, FP, FN, TN, roc_auc\n",
    "    sum_TP, sum_FP, sum_FN, sum_TN, roc_auc_scores_test = make_cm_list_5(cm_test_list)\n",
    "    roc_auc_scores_test_list.append(roc_auc_scores_test)\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "roc_auc_scores_test_list_list.append(roc_auc_scores_test_list)\n",
    "base_score_list_list.append(base_score_list)\n",
    "max_count_score_list_list.append(max_count_score_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c5ddcf",
   "metadata": {},
   "source": [
    "# Calculate confidence intervals using bootstrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38caa2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]\n",
      "scikit-learn version: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f164662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group1:\n",
      "  AUC Mean: 0.6742, 95% CI: (0.6083, 0.7367)\n",
      "\n",
      "Group2:\n",
      "  AUC Mean: 0.6516, 95% CI: (0.5255, 0.7605)\n",
      "\n",
      "Group3:\n",
      "  AUC Mean: 0.5594, 95% CI: (0.5034, 0.6149)\n",
      "\n",
      "Group4:\n",
      "  AUC Mean: 0.6405, 95% CI: (0.5557, 0.7210)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, cohen_kappa_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Define the confusion matrix values for each group\n",
    "# TP, FP, FN, TN\n",
    "confusion_matrices = [\n",
    "    (48, 68, 19, 116),  # Group1\n",
    "    (11, 114, 3, 123),  # Group2\n",
    "    (77, 102, 21, 51),  # Group3\n",
    "    (24, 79, 13, 135)   # Group4\n",
    "]\n",
    "\n",
    "# Number of bootstrap iterations and confidence level\n",
    "n_iterations = 10000\n",
    "alpha = 0.05\n",
    "\n",
    "# Function to calculate bootstrap confidence intervals\n",
    "def bootstrap_confidence_intervals(matrix):\n",
    "    TP, FP, FN, TN = matrix\n",
    "\n",
    "    # Actual labels and predicted labels\n",
    "    y_true = np.concatenate([np.ones(TP + FN), np.zeros(FP + TN)])\n",
    "    y_pred = np.concatenate([np.ones(TP), np.zeros(FN), np.ones(FP), np.zeros(TN)])\n",
    "\n",
    "    aucs = []\n",
    "    \n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Resample\n",
    "        y_true_sample, y_pred_sample = resample(y_true, y_pred)\n",
    "\n",
    "        # Calculate AUC\n",
    "        auc = roc_auc_score(y_true_sample, y_pred_sample)\n",
    "        aucs.append(auc)\n",
    "\n",
    "\n",
    "    # Sort and calculate confidence intervals\n",
    "    aucs.sort()\n",
    "\n",
    "    lower_idx = int(n_iterations * alpha / 2)\n",
    "    upper_idx = int(n_iterations * (1 - alpha / 2))\n",
    "\n",
    "    # Calculate mean and confidence intervals\n",
    "    results = {\n",
    "        'AUC Mean': np.mean(aucs),\n",
    "        'AUC CI': (aucs[lower_idx], aucs[upper_idx]),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# Calculate and store results for each group\n",
    "group_results = {}\n",
    "for i, matrix in enumerate(confusion_matrices):\n",
    "    group_results[f'Group{i + 1}'] = bootstrap_confidence_intervals(matrix)\n",
    "\n",
    "# Print results for each group with formatting\n",
    "for group, results in group_results.items():\n",
    "    print(f\"{group}:\")\n",
    "    print(f\"  AUC Mean: {results['AUC Mean']:.4f}, 95% CI: ({results['AUC CI'][0]:.4f}, {results['AUC CI'][1]:.4f})\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
